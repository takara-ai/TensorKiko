{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKPT File Investigation\n",
    "\n",
    "This notebook is designed to investigate and troubleshoot issues with loading CKPT files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/TensorKiko/requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r /TensorKiko/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import struct\n",
    "\n",
    "def check_file(ckpt_path):\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        print(f\"File not found: {ckpt_path}\")\n",
    "        return False\n",
    "    print(f\"File found: {ckpt_path}\")\n",
    "    print(f\"File size: {os.path.getsize(ckpt_path) / (1024 * 1024):.2f} MB\")\n",
    "    return True\n",
    "\n",
    "def try_load_ckpt(file_path, encoding=None):\n",
    "    try:\n",
    "        if encoding:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                state_dict = torch.load(f, map_location=\"cpu\", encoding=encoding)\n",
    "        else:\n",
    "            state_dict = torch.load(file_path, map_location=\"cpu\")\n",
    "        print(\"Successfully loaded the checkpoint.\")\n",
    "        return state_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load the checkpoint. Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def inspect_file_header(file_path, num_bytes=100):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        header = f.read(num_bytes)\n",
    "    print(f\"First {num_bytes} bytes of the file:\")\n",
    "    print(header)\n",
    "    print(\"\\nAs ASCII:\")\n",
    "    print(''.join(chr(b) if 32 <= b < 127 else '.' for b in header))\n",
    "\n",
    "def try_manual_unpickle(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(\"Successfully unpickled the file.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to unpickle the file. Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def investigate_ckpt(ckpt_path):\n",
    "    if not check_file(ckpt_path):\n",
    "        return\n",
    "\n",
    "    print(\"\\nAttempting to load with default settings...\")\n",
    "    state_dict = try_load_ckpt(ckpt_path)\n",
    "\n",
    "    if state_dict is None:\n",
    "        print(\"\\nAttempting to load with 'latin1' encoding...\")\n",
    "        state_dict = try_load_ckpt(ckpt_path, encoding='latin1')\n",
    "\n",
    "    print(\"\\nInspecting file header:\")\n",
    "    inspect_file_header(ckpt_path)\n",
    "\n",
    "    print(\"\\nAttempting manual unpickling:\")\n",
    "    manual_unpickled = try_manual_unpickle(ckpt_path)\n",
    "\n",
    "    if state_dict is not None:\n",
    "        print(\"\\nCheckpoint loaded successfully. Here's a summary of its contents:\")\n",
    "        for key, value in state_dict.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                print(f\"{key}: Tensor of shape {value.shape}\")\n",
    "            else:\n",
    "                print(f\"{key}: {type(value)}\")\n",
    "    else:\n",
    "        print(\"\\nUnable to load the checkpoint. You may need to implement a custom loading function based on the file structure.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ckpt_path = 'clip_vit_l14_vision_model_f16.ckpt'  # Replace with your file path\n",
    "    investigate_ckpt(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import torch\n",
    "import io\n",
    "\n",
    "def investigate_sqlite_ckpt(file_path):\n",
    "    print(f\"Investigating SQLite file: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        conn = sqlite3.connect(file_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Get list of tables\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "        \n",
    "        print(\"\\nTables found in the database:\")\n",
    "        for table in tables:\n",
    "            print(table[0])\n",
    "        \n",
    "        # Assuming there's a table named 'weights' or similar\n",
    "        table_name = tables[0][0] if tables else None\n",
    "        \n",
    "        if table_name:\n",
    "            print(f\"\\nInvestigating table: {table_name}\")\n",
    "            \n",
    "            # Get column information\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "            columns = cursor.fetchall()\n",
    "            print(\"\\nColumns:\")\n",
    "            for column in columns:\n",
    "                print(f\"  {column[1]} ({column[2]})\")\n",
    "            \n",
    "            # Fetch a sample row\n",
    "            cursor.execute(f\"SELECT * FROM {table_name} LIMIT 1\")\n",
    "            sample_row = cursor.fetchone()\n",
    "            \n",
    "            if sample_row:\n",
    "                print(\"\\nSample row:\")\n",
    "                for i, value in enumerate(sample_row):\n",
    "                    print(f\"  {columns[i][1]}: {type(value)}\")\n",
    "                \n",
    "                # If there's a column that might contain tensor data (e.g., 'weight' or 'value')\n",
    "                tensor_column = next((col[1] for col in columns if col[1].lower() in ['weight', 'value', 'tensor']), None)\n",
    "                \n",
    "                if tensor_column:\n",
    "                    print(f\"\\nAttempting to load a tensor from the '{tensor_column}' column...\")\n",
    "                    cursor.execute(f\"SELECT {tensor_column} FROM {table_name} LIMIT 1\")\n",
    "                    tensor_data = cursor.fetchone()[0]\n",
    "                    \n",
    "                    try:\n",
    "                        tensor = torch.load(io.BytesIO(tensor_data))\n",
    "                        print(f\"Successfully loaded a tensor of shape: {tensor.shape}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to load tensor: {str(e)}\")\n",
    "            else:\n",
    "                print(\"No data found in the table.\")\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error investigating the SQLite file: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ckpt_path = 'clip_vit_l14_vision_model_f16.ckpt'  # Replace with your file path\n",
    "    investigate_sqlite_ckpt(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import torch\n",
    "import io\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def parse_tensor_data(data_blob, dim):\n",
    "    # Try different methods to interpret the data\n",
    "    methods = [\n",
    "        lambda: torch.from_numpy(np.frombuffer(data_blob, dtype=np.float32).reshape(dim)),\n",
    "        lambda: torch.from_numpy(np.frombuffer(data_blob, dtype=np.float16).reshape(dim)),\n",
    "        lambda: torch.load(io.BytesIO(data_blob)),\n",
    "        lambda: torch.tensor(struct.unpack(f'{len(data_blob)//4}f', data_blob)).reshape(dim)\n",
    "    ]\n",
    "    \n",
    "    for method in methods:\n",
    "        try:\n",
    "            return method()\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    raise ValueError(\"Unable to parse tensor data\")\n",
    "\n",
    "def load_sqlite_ckpt(file_path):\n",
    "    print(f\"Loading SQLite-based checkpoint: {file_path}\")\n",
    "    \n",
    "    state_dict = {}\n",
    "    \n",
    "    try:\n",
    "        conn = sqlite3.connect(file_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\"SELECT name, dim, data FROM tensors\")\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        for name, dim_blob, data_blob in rows:\n",
    "            # Parse dimension\n",
    "            dim = struct.unpack('!' + 'q' * (len(dim_blob) // 8), dim_blob)\n",
    "            \n",
    "            try:\n",
    "                # Attempt to load tensor data\n",
    "                tensor = parse_tensor_data(data_blob, dim)\n",
    "                \n",
    "                # Verify shape\n",
    "                if tensor.shape != dim:\n",
    "                    print(f\"Warning: Shape mismatch for {name}. Expected {dim}, got {tensor.shape}\")\n",
    "                \n",
    "                state_dict[name] = tensor\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading tensor {name}: {str(e)}\")\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        print(f\"Successfully loaded {len(state_dict)} tensors\")\n",
    "        return state_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the SQLite-based checkpoint: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ckpt_path = 'clip_vit_l14_vision_model_f16.ckpt'  # Replace with your file path\n",
    "    state_dict = load_sqlite_ckpt(ckpt_path)\n",
    "    \n",
    "    if state_dict:\n",
    "        print(\"\\nCheckpoint contents:\")\n",
    "        for name, tensor in state_dict.items():\n",
    "            print(f\"{name}: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all previous attempts fail, you may need to implement a custom loading function based on the file structure. This would require more in-depth analysis of the file format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
